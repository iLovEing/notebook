# [声纹识别](https://github.com/iLovEing/notebook/issues/23)

声纹的概念来自于指纹，广义上讲，可以将一个\一类声音和其他声音区分开来的特征，都可以认为是声纹特征。这里主要记录声纹识别相关的技术发展和工程应用
> 摘录自《声纹技术：从核心算法到工程实践》



---

## 声纹技术的前世今生
![screenshot-20230816-144619](https://github.com/iLovEing/notebook/assets/109459299/ba823866-098f-44f7-bd54-a911daf3d3c7)

1. 早期声纹技术使用直观的向量化-匹配差异的思路，将音频转化为时频谱矩阵或**梅尔倒谱系数**，继而使用向量/矩阵求的距离的手段来对音频识别分类。
2. 1995~2006年，在GMM出现后，**GMM-HMM**, **GMM-UBM**, **GMM-SVM** 等技术相继运用到声纹识别上，这个阶段是声纹识别的高斯混合模型时代。
3. 2007-2011 **联合因子分析(JFA)**与**i-vector**被提出，其充分考虑了信道的变化因素，将每个说话人的模型从高斯混合模型的多个分量中，映射到了更加低维的表征空间，从而克服了高斯分量互相独立的局限性。
4. 14年以后，随着深度学习技术的爆发，**LSTM**、**attention**等网络结构被越来越多地用到声音处理上。

> 下面对其中重要的概念和方法做简单的介绍

---

## 音频相关的基础概念

### 1. 声学基础
- **正弦波**
$y = Asin(2\pi fx + \varphi )$
其中，*f* 为频率，  $2\pi f$ 为角频率， $2\pi fx + \varphi$ 为相位， $\varphi$ 为初始相位

- **频谱**
复杂的波形可以通过[fft](https://github.com/iLovEing/notebook/issues/11)分解为许多个正弦波的叠加，因此我们可以画出这样一张图，其横轴为这些正弦波分量的频率，纵轴为这些正弦波分量的振幅,这样的图就是频谱。

- **基音**与**基频**
复杂声音中最低且通常情况下最强的频率，我理解为声音的基础“音调”

- **功率**与**声强**
假设周期信号为 $y=f(t)$ ，声音的功率可以表示为：
$P=\frac{1}{T}\int_{0}^{T}(f(t))^{2}dt$
声强定义为：
$L_{dB} =10\log_{10}{\frac{P}{P_{0}} } $ ，定义为分贝