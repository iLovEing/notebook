# [声纹识别](https://github.com/iLovEing/notebook/issues/23)

声纹的概念来自于指纹，广义上讲，可以将一个\一类声音和其他声音区分开来的特征，都可以认为是声纹特征。这里主要记录声纹识别相关的技术发展和工程应用
> 摘录自《声纹技术：从核心算法到工程实践》



---

## 声纹技术的前世今生
![screenshot-20230816-144619](https://github.com/iLovEing/notebook/assets/109459299/ba823866-098f-44f7-bd54-a911daf3d3c7)

1. 早期声纹技术使用直观的向量化-匹配差异的思路，将音频转化为时频谱矩阵或**梅尔倒谱系数**，继而使用向量/矩阵求的距离的手段来对音频识别分类。
2. 1995~2006年，在GMM出现后，**GMM-HMM**, **GMM-UBM**, **GMM-SVM** 等技术相继运用到声纹识别上，这个阶段是声纹识别的高斯混合模型时代。
3. 2007-2011 **联合因子分析(JFA)**与**i-vector**被提出，其充分考虑了信道的变化因素，将每个说话人的模型从高斯混合模型的多个分量中，映射到了更加低维的表征空间，从而克服了高斯分量互相独立的局限性。
4. 14年以后，随着深度学习技术的爆发，**LSTM**、**attention**等网络结构被越来越多地用到声音处理上。

> 下面对其中重要的概念和方法做简单的介绍

---

## 音频相关的基础概念

### 1. 声学基础
- **正弦波**
$y = Asin(2\pi fx + \varphi )$
其中，*f* 为频率，  $2\pi f$ 为角频率， $2\pi fx + \varphi$ 为相位， $\varphi$ 为初始相位

- **频谱**
复杂的波形可以通过[fft](https://github.com/iLovEing/notebook/issues/11)分解为许多个正弦波的叠加，因此我们可以画出这样一张图，其横轴为这些正弦波分量的频率，纵轴为这些正弦波分量的振幅,这样的图就是频谱。

- **基音**与**基频**
复杂声音中最低且通常情况下最强的频率，我理解为声音的基础“音调”

- **功率**与**声强**
假设周期信号为 $y=f(t)$ ，声音的功率可以表示为：
$P=\frac{1}{T}\int_{0}^{T}(f(t))^{2}dt$
声强定义为：  
$L_{dB} =10\log_{10}{\frac{P}{P_{0}}} $单位为分贝， $P_{0}$ 为人耳能听到的最小分贝

---

### 2. 数字信号-计算机如何存储？
将连续的模拟信号转换为离散的数字信号有两个步骤：采样和量化。再使用一定的编码规则转换成最后的音频文件。

- **采样**
采样是指对模拟信号进行周期性采样，给定一个采样率，能重建的周期信号的频率是该采样率的一半（波峰一次，波谷一次）。
![image](https://github.com/iLovEing/notebook/assets/109459299/a6e8c7b4-ded7-41bf-8912-4e50e6ac43df)

- **量化**
信号经过采样之后，得到时间轴上每个点的幅值，在计算机上保存时，会用一定位数的存储空间保存（二进制），比如8位，这时所有的幅值都用这个8位二进制来表示，就是8位量化，量化意味着精度的损失。

- **编码**
量化时具体的映射关系即编码规则，比如最简单的线性脉冲编码(liner PCM)，其在量化时相邻整数表示的信号差值固定，即信号在映射到量化区域上是均匀且线性的。常见的编码规则有：线性编码、非线性编码、自适应编码、差分编码（对相邻信号差做量化），频域编码等